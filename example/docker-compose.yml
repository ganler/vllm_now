x-vllm-server-base: &vllm-server-base
  image: vllm/vllm-openai:latest
  ipc: host
  command:
    - --disable-log-requests   # To save your eyes from the logs
    - --model=ise-uiuc/Magicoder-S-DS-6.7B
  volumes:
    - /opt/dlami/nvme/huggingface:/root/.cache/huggingface:rw
    - /home/ubuntu/.cache/hf_hub_token:/root/.cache/hf_hub_token
  environment:
    - HF_TOKEN_PATH=/root/.cache/hf_hub_token

services:
  vllm-server-0:
    <<: *vllm-server-base
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ['0']

  load-balancer:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - vllm-server-0
